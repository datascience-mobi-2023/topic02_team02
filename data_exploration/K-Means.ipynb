{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-30T10:33:54.961033Z",
     "start_time": "2023-06-30T10:33:54.669055600Z"
    }
   },
   "outputs": [],
   "source": [
    "# ich dachte ich kopiere hier einfach schonmal den Code von dem Python Intro rÃ¼ber, dann gehts schneller, wenn wir hier wirklich anfangen dran zu arbeiten\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "#... startet bei Iteration 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = np.random.randint(0,101,(100,2))\n",
    "centers = np.random.randint(0,101,(4,2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T23:13:49.490586Z",
     "start_time": "2023-06-08T23:13:49.489535Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "clusters = np.expand_dims(centers, axis=1)\n",
    "data = np.expand_dims(data, axis=0)\n",
    "\n",
    "eucl = np.linalg.norm(clusters - data, axis=2)\n",
    "\n",
    "labels = np.argmin(eucl, axis = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T23:13:49.493187Z",
     "start_time": "2023-06-08T23:13:49.491913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calc_distance(data,centers):\n",
    "    clusters = np.expand_dims(centers, axis=1)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "\n",
    "    eucl = np.linalg.norm(clusters - data, axis=2)\n",
    "\n",
    "    labels = np.argmin(eucl, axis = 0)\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T23:13:49.495896Z",
     "start_time": "2023-06-08T23:13:49.494717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAxisError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mcalc_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m, in \u001B[0;36mcalc_distance\u001B[0;34m(data, centers)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalc_distance\u001B[39m(data,centers):\n\u001B[0;32m----> 2\u001B[0m     clusters \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcenters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(data, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      5\u001B[0m     eucl \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(clusters \u001B[38;5;241m-\u001B[39m data, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n",
      "File \u001B[0;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mexpand_dims\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Downloads/Users/dario/MambaMentality/envs/dms/lib/python3.10/site-packages/numpy/lib/shape_base.py:597\u001B[0m, in \u001B[0;36mexpand_dims\u001B[0;34m(a, axis)\u001B[0m\n\u001B[1;32m    594\u001B[0m     axis \u001B[38;5;241m=\u001B[39m (axis,)\n\u001B[1;32m    596\u001B[0m out_ndim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(axis) \u001B[38;5;241m+\u001B[39m a\u001B[38;5;241m.\u001B[39mndim\n\u001B[0;32m--> 597\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[43mnormalize_axis_tuple\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_ndim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    599\u001B[0m shape_it \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(a\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m    600\u001B[0m shape \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ax \u001B[38;5;129;01min\u001B[39;00m axis \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(shape_it) \u001B[38;5;28;01mfor\u001B[39;00m ax \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(out_ndim)]\n",
      "File \u001B[0;32m~/Downloads/Users/dario/MambaMentality/envs/dms/lib/python3.10/site-packages/numpy/core/numeric.py:1398\u001B[0m, in \u001B[0;36mnormalize_axis_tuple\u001B[0;34m(axis, ndim, argname, allow_duplicate)\u001B[0m\n\u001B[1;32m   1396\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001B[39;00m\n\u001B[0;32m-> 1398\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m([normalize_axis_index(ax, ndim, argname) \u001B[38;5;28;01mfor\u001B[39;00m ax \u001B[38;5;129;01min\u001B[39;00m axis])\n\u001B[1;32m   1399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_duplicate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(axis)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(axis):\n\u001B[1;32m   1400\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m argname:\n",
      "File \u001B[0;32m~/Downloads/Users/dario/MambaMentality/envs/dms/lib/python3.10/site-packages/numpy/core/numeric.py:1398\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1396\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1397\u001B[0m \u001B[38;5;66;03m# Going via an iterator directly is slower than via list comprehension.\u001B[39;00m\n\u001B[0;32m-> 1398\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m([\u001B[43mnormalize_axis_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margname\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m ax \u001B[38;5;129;01min\u001B[39;00m axis])\n\u001B[1;32m   1399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_duplicate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mset\u001B[39m(axis)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(axis):\n\u001B[1;32m   1400\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m argname:\n",
      "\u001B[0;31mAxisError\u001B[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "calc_distance(data, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T23:13:49.822031Z",
     "start_time": "2023-06-08T23:13:49.496788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# k-means mit scikit learn library\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import data_exploration as de\n",
    "import data_cleanup as dc\n",
    "from time import time\n",
    "import functions as fun"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T10:47:01.739417Z",
     "start_time": "2023-06-30T10:47:01.414888800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "AS_old         A         C         D         E         F         G         H   \nAS_old                                                                         \nA       0.000000  1.845023  0.377937  0.422263  0.484488  0.453102  0.885071  \\\nC       1.845023  0.000000  1.739546  1.693797  1.568963  1.592610  1.195729   \nD       0.377937  1.739546  0.000000  0.355713  0.436921  0.451473  0.787570   \nE       0.422263  1.693797  0.355713  0.000000  0.411267  0.418142  0.699191   \nF       0.484488  1.568963  0.436921  0.411267  0.000000  0.360663  0.557544   \nG       0.453102  1.592610  0.451473  0.418142  0.360663  0.000000  0.659749   \nH       0.885071  1.195729  0.787570  0.699191  0.557544  0.659749  0.000000   \nI       1.315256  0.893504  1.179766  1.144296  1.053084  1.109575  0.756021   \nK       0.450027  2.124593  0.478785  0.631467  0.725772  0.688432  1.138538   \nL       0.319937  1.716395  0.292915  0.316790  0.425806  0.402772  0.772620   \nM       0.647783  1.332638  0.587418  0.551906  0.483683  0.511603  0.492955   \nN       0.579572  1.456023  0.604502  0.503716  0.490412  0.458746  0.602867   \nP       0.376269  1.723635  0.370503  0.360214  0.384107  0.404120  0.752086   \nQ       0.303319  1.877115  0.396478  0.427622  0.530136  0.410635  0.932305   \nR       0.615500  1.411988  0.585682  0.538216  0.444300  0.519944  0.591549   \nS       0.382538  1.696741  0.333661  0.277137  0.430056  0.370723  0.743994   \nT       0.532855  1.529327  0.418055  0.355378  0.385896  0.379697  0.604865   \nV       1.383635  0.776950  1.256460  1.200096  1.095778  1.143112  0.816655   \nW       0.474408  1.679513  0.420888  0.402335  0.308844  0.489493  0.681989   \nY       1.654408  0.862319  1.565089  1.474623  1.303579  1.403907  0.986374   \n\nAS_old         I         K         L         M         N         P         Q   \nAS_old                                                                         \nA       1.315256  0.450027  0.319937  0.647783  0.579572  0.376269  0.303319  \\\nC       0.893504  2.124593  1.716395  1.332638  1.456023  1.723635  1.877115   \nD       1.179766  0.478785  0.292915  0.587418  0.604502  0.370503  0.396478   \nE       1.144296  0.631467  0.316790  0.551906  0.503716  0.360214  0.427622   \nF       1.053084  0.725772  0.425806  0.483683  0.490412  0.384107  0.530136   \nG       1.109575  0.688432  0.402772  0.511603  0.458746  0.404120  0.410635   \nH       0.756021  1.138538  0.772620  0.492955  0.602867  0.752086  0.932305   \nI       0.000000  1.560230  1.125003  0.826347  1.008605  1.185265  1.345954   \nK       1.560230  0.000000  0.541761  0.949036  0.928907  0.554754  0.464411   \nL       1.125003  0.541761  0.000000  0.572762  0.519740  0.369675  0.394939   \nM       0.826347  0.949036  0.572762  0.000000  0.501798  0.571707  0.678155   \nN       1.008605  0.928907  0.519740  0.501798  0.000000  0.576200  0.627439   \nP       1.185265  0.554754  0.369675  0.571707  0.576200  0.000000  0.410122   \nQ       1.345954  0.464411  0.394939  0.678155  0.627439  0.410122  0.000000   \nR       0.898532  0.937452  0.544512  0.411414  0.338219  0.563475  0.705152   \nS       1.170509  0.554908  0.321409  0.584640  0.474905  0.349089  0.394980   \nT       1.012057  0.743065  0.409099  0.469271  0.434238  0.454267  0.515261   \nV       0.527745  1.612262  1.212038  0.916607  1.014060  1.208011  1.380806   \nW       1.109897  0.649373  0.374314  0.625049  0.591486  0.425722  0.521980   \nY       0.819301  1.912586  1.496523  1.227827  1.301236  1.518396  1.676351   \n\nAS_old         R         S         T         V         W         Y  \nAS_old                                                              \nA       0.615500  0.382538  0.532855  1.383635  0.474408  1.654408  \nC       1.411988  1.696741  1.529327  0.776950  1.679513  0.862319  \nD       0.585682  0.333661  0.418055  1.256460  0.420888  1.565089  \nE       0.538216  0.277137  0.355378  1.200096  0.402335  1.474623  \nF       0.444300  0.430056  0.385896  1.095778  0.308844  1.303579  \nG       0.519944  0.370723  0.379697  1.143112  0.489493  1.403907  \nH       0.591549  0.743994  0.604865  0.816655  0.681989  0.986374  \nI       0.898532  1.170509  1.012057  0.527745  1.109897  0.819301  \nK       0.937452  0.554908  0.743065  1.612262  0.649373  1.912586  \nL       0.544512  0.321409  0.409099  1.212038  0.374314  1.496523  \nM       0.411414  0.584640  0.469271  0.916607  0.625049  1.227827  \nN       0.338219  0.474905  0.434238  1.014060  0.591486  1.301236  \nP       0.563475  0.349089  0.454267  1.208011  0.425722  1.518396  \nQ       0.705152  0.394980  0.515261  1.380806  0.521980  1.676351  \nR       0.000000  0.512081  0.436648  0.959603  0.565894  1.243503  \nS       0.512081  0.000000  0.372986  1.207539  0.416941  1.493415  \nT       0.436648  0.372986  0.000000  1.035909  0.420829  1.337322  \nV       0.959603  1.207539  1.035909  0.000000  1.179253  0.834440  \nW       0.565894  0.416941  0.420829  1.179253  0.000000  1.348876  \nY       1.243503  1.493415  1.337322  0.834440  1.348876  0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>AS_old</th>\n      <th>A</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>F</th>\n      <th>G</th>\n      <th>H</th>\n      <th>I</th>\n      <th>K</th>\n      <th>L</th>\n      <th>M</th>\n      <th>N</th>\n      <th>P</th>\n      <th>Q</th>\n      <th>R</th>\n      <th>S</th>\n      <th>T</th>\n      <th>V</th>\n      <th>W</th>\n      <th>Y</th>\n    </tr>\n    <tr>\n      <th>AS_old</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A</th>\n      <td>0.000000</td>\n      <td>1.845023</td>\n      <td>0.377937</td>\n      <td>0.422263</td>\n      <td>0.484488</td>\n      <td>0.453102</td>\n      <td>0.885071</td>\n      <td>1.315256</td>\n      <td>0.450027</td>\n      <td>0.319937</td>\n      <td>0.647783</td>\n      <td>0.579572</td>\n      <td>0.376269</td>\n      <td>0.303319</td>\n      <td>0.615500</td>\n      <td>0.382538</td>\n      <td>0.532855</td>\n      <td>1.383635</td>\n      <td>0.474408</td>\n      <td>1.654408</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>1.845023</td>\n      <td>0.000000</td>\n      <td>1.739546</td>\n      <td>1.693797</td>\n      <td>1.568963</td>\n      <td>1.592610</td>\n      <td>1.195729</td>\n      <td>0.893504</td>\n      <td>2.124593</td>\n      <td>1.716395</td>\n      <td>1.332638</td>\n      <td>1.456023</td>\n      <td>1.723635</td>\n      <td>1.877115</td>\n      <td>1.411988</td>\n      <td>1.696741</td>\n      <td>1.529327</td>\n      <td>0.776950</td>\n      <td>1.679513</td>\n      <td>0.862319</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>0.377937</td>\n      <td>1.739546</td>\n      <td>0.000000</td>\n      <td>0.355713</td>\n      <td>0.436921</td>\n      <td>0.451473</td>\n      <td>0.787570</td>\n      <td>1.179766</td>\n      <td>0.478785</td>\n      <td>0.292915</td>\n      <td>0.587418</td>\n      <td>0.604502</td>\n      <td>0.370503</td>\n      <td>0.396478</td>\n      <td>0.585682</td>\n      <td>0.333661</td>\n      <td>0.418055</td>\n      <td>1.256460</td>\n      <td>0.420888</td>\n      <td>1.565089</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>0.422263</td>\n      <td>1.693797</td>\n      <td>0.355713</td>\n      <td>0.000000</td>\n      <td>0.411267</td>\n      <td>0.418142</td>\n      <td>0.699191</td>\n      <td>1.144296</td>\n      <td>0.631467</td>\n      <td>0.316790</td>\n      <td>0.551906</td>\n      <td>0.503716</td>\n      <td>0.360214</td>\n      <td>0.427622</td>\n      <td>0.538216</td>\n      <td>0.277137</td>\n      <td>0.355378</td>\n      <td>1.200096</td>\n      <td>0.402335</td>\n      <td>1.474623</td>\n    </tr>\n    <tr>\n      <th>F</th>\n      <td>0.484488</td>\n      <td>1.568963</td>\n      <td>0.436921</td>\n      <td>0.411267</td>\n      <td>0.000000</td>\n      <td>0.360663</td>\n      <td>0.557544</td>\n      <td>1.053084</td>\n      <td>0.725772</td>\n      <td>0.425806</td>\n      <td>0.483683</td>\n      <td>0.490412</td>\n      <td>0.384107</td>\n      <td>0.530136</td>\n      <td>0.444300</td>\n      <td>0.430056</td>\n      <td>0.385896</td>\n      <td>1.095778</td>\n      <td>0.308844</td>\n      <td>1.303579</td>\n    </tr>\n    <tr>\n      <th>G</th>\n      <td>0.453102</td>\n      <td>1.592610</td>\n      <td>0.451473</td>\n      <td>0.418142</td>\n      <td>0.360663</td>\n      <td>0.000000</td>\n      <td>0.659749</td>\n      <td>1.109575</td>\n      <td>0.688432</td>\n      <td>0.402772</td>\n      <td>0.511603</td>\n      <td>0.458746</td>\n      <td>0.404120</td>\n      <td>0.410635</td>\n      <td>0.519944</td>\n      <td>0.370723</td>\n      <td>0.379697</td>\n      <td>1.143112</td>\n      <td>0.489493</td>\n      <td>1.403907</td>\n    </tr>\n    <tr>\n      <th>H</th>\n      <td>0.885071</td>\n      <td>1.195729</td>\n      <td>0.787570</td>\n      <td>0.699191</td>\n      <td>0.557544</td>\n      <td>0.659749</td>\n      <td>0.000000</td>\n      <td>0.756021</td>\n      <td>1.138538</td>\n      <td>0.772620</td>\n      <td>0.492955</td>\n      <td>0.602867</td>\n      <td>0.752086</td>\n      <td>0.932305</td>\n      <td>0.591549</td>\n      <td>0.743994</td>\n      <td>0.604865</td>\n      <td>0.816655</td>\n      <td>0.681989</td>\n      <td>0.986374</td>\n    </tr>\n    <tr>\n      <th>I</th>\n      <td>1.315256</td>\n      <td>0.893504</td>\n      <td>1.179766</td>\n      <td>1.144296</td>\n      <td>1.053084</td>\n      <td>1.109575</td>\n      <td>0.756021</td>\n      <td>0.000000</td>\n      <td>1.560230</td>\n      <td>1.125003</td>\n      <td>0.826347</td>\n      <td>1.008605</td>\n      <td>1.185265</td>\n      <td>1.345954</td>\n      <td>0.898532</td>\n      <td>1.170509</td>\n      <td>1.012057</td>\n      <td>0.527745</td>\n      <td>1.109897</td>\n      <td>0.819301</td>\n    </tr>\n    <tr>\n      <th>K</th>\n      <td>0.450027</td>\n      <td>2.124593</td>\n      <td>0.478785</td>\n      <td>0.631467</td>\n      <td>0.725772</td>\n      <td>0.688432</td>\n      <td>1.138538</td>\n      <td>1.560230</td>\n      <td>0.000000</td>\n      <td>0.541761</td>\n      <td>0.949036</td>\n      <td>0.928907</td>\n      <td>0.554754</td>\n      <td>0.464411</td>\n      <td>0.937452</td>\n      <td>0.554908</td>\n      <td>0.743065</td>\n      <td>1.612262</td>\n      <td>0.649373</td>\n      <td>1.912586</td>\n    </tr>\n    <tr>\n      <th>L</th>\n      <td>0.319937</td>\n      <td>1.716395</td>\n      <td>0.292915</td>\n      <td>0.316790</td>\n      <td>0.425806</td>\n      <td>0.402772</td>\n      <td>0.772620</td>\n      <td>1.125003</td>\n      <td>0.541761</td>\n      <td>0.000000</td>\n      <td>0.572762</td>\n      <td>0.519740</td>\n      <td>0.369675</td>\n      <td>0.394939</td>\n      <td>0.544512</td>\n      <td>0.321409</td>\n      <td>0.409099</td>\n      <td>1.212038</td>\n      <td>0.374314</td>\n      <td>1.496523</td>\n    </tr>\n    <tr>\n      <th>M</th>\n      <td>0.647783</td>\n      <td>1.332638</td>\n      <td>0.587418</td>\n      <td>0.551906</td>\n      <td>0.483683</td>\n      <td>0.511603</td>\n      <td>0.492955</td>\n      <td>0.826347</td>\n      <td>0.949036</td>\n      <td>0.572762</td>\n      <td>0.000000</td>\n      <td>0.501798</td>\n      <td>0.571707</td>\n      <td>0.678155</td>\n      <td>0.411414</td>\n      <td>0.584640</td>\n      <td>0.469271</td>\n      <td>0.916607</td>\n      <td>0.625049</td>\n      <td>1.227827</td>\n    </tr>\n    <tr>\n      <th>N</th>\n      <td>0.579572</td>\n      <td>1.456023</td>\n      <td>0.604502</td>\n      <td>0.503716</td>\n      <td>0.490412</td>\n      <td>0.458746</td>\n      <td>0.602867</td>\n      <td>1.008605</td>\n      <td>0.928907</td>\n      <td>0.519740</td>\n      <td>0.501798</td>\n      <td>0.000000</td>\n      <td>0.576200</td>\n      <td>0.627439</td>\n      <td>0.338219</td>\n      <td>0.474905</td>\n      <td>0.434238</td>\n      <td>1.014060</td>\n      <td>0.591486</td>\n      <td>1.301236</td>\n    </tr>\n    <tr>\n      <th>P</th>\n      <td>0.376269</td>\n      <td>1.723635</td>\n      <td>0.370503</td>\n      <td>0.360214</td>\n      <td>0.384107</td>\n      <td>0.404120</td>\n      <td>0.752086</td>\n      <td>1.185265</td>\n      <td>0.554754</td>\n      <td>0.369675</td>\n      <td>0.571707</td>\n      <td>0.576200</td>\n      <td>0.000000</td>\n      <td>0.410122</td>\n      <td>0.563475</td>\n      <td>0.349089</td>\n      <td>0.454267</td>\n      <td>1.208011</td>\n      <td>0.425722</td>\n      <td>1.518396</td>\n    </tr>\n    <tr>\n      <th>Q</th>\n      <td>0.303319</td>\n      <td>1.877115</td>\n      <td>0.396478</td>\n      <td>0.427622</td>\n      <td>0.530136</td>\n      <td>0.410635</td>\n      <td>0.932305</td>\n      <td>1.345954</td>\n      <td>0.464411</td>\n      <td>0.394939</td>\n      <td>0.678155</td>\n      <td>0.627439</td>\n      <td>0.410122</td>\n      <td>0.000000</td>\n      <td>0.705152</td>\n      <td>0.394980</td>\n      <td>0.515261</td>\n      <td>1.380806</td>\n      <td>0.521980</td>\n      <td>1.676351</td>\n    </tr>\n    <tr>\n      <th>R</th>\n      <td>0.615500</td>\n      <td>1.411988</td>\n      <td>0.585682</td>\n      <td>0.538216</td>\n      <td>0.444300</td>\n      <td>0.519944</td>\n      <td>0.591549</td>\n      <td>0.898532</td>\n      <td>0.937452</td>\n      <td>0.544512</td>\n      <td>0.411414</td>\n      <td>0.338219</td>\n      <td>0.563475</td>\n      <td>0.705152</td>\n      <td>0.000000</td>\n      <td>0.512081</td>\n      <td>0.436648</td>\n      <td>0.959603</td>\n      <td>0.565894</td>\n      <td>1.243503</td>\n    </tr>\n    <tr>\n      <th>S</th>\n      <td>0.382538</td>\n      <td>1.696741</td>\n      <td>0.333661</td>\n      <td>0.277137</td>\n      <td>0.430056</td>\n      <td>0.370723</td>\n      <td>0.743994</td>\n      <td>1.170509</td>\n      <td>0.554908</td>\n      <td>0.321409</td>\n      <td>0.584640</td>\n      <td>0.474905</td>\n      <td>0.349089</td>\n      <td>0.394980</td>\n      <td>0.512081</td>\n      <td>0.000000</td>\n      <td>0.372986</td>\n      <td>1.207539</td>\n      <td>0.416941</td>\n      <td>1.493415</td>\n    </tr>\n    <tr>\n      <th>T</th>\n      <td>0.532855</td>\n      <td>1.529327</td>\n      <td>0.418055</td>\n      <td>0.355378</td>\n      <td>0.385896</td>\n      <td>0.379697</td>\n      <td>0.604865</td>\n      <td>1.012057</td>\n      <td>0.743065</td>\n      <td>0.409099</td>\n      <td>0.469271</td>\n      <td>0.434238</td>\n      <td>0.454267</td>\n      <td>0.515261</td>\n      <td>0.436648</td>\n      <td>0.372986</td>\n      <td>0.000000</td>\n      <td>1.035909</td>\n      <td>0.420829</td>\n      <td>1.337322</td>\n    </tr>\n    <tr>\n      <th>V</th>\n      <td>1.383635</td>\n      <td>0.776950</td>\n      <td>1.256460</td>\n      <td>1.200096</td>\n      <td>1.095778</td>\n      <td>1.143112</td>\n      <td>0.816655</td>\n      <td>0.527745</td>\n      <td>1.612262</td>\n      <td>1.212038</td>\n      <td>0.916607</td>\n      <td>1.014060</td>\n      <td>1.208011</td>\n      <td>1.380806</td>\n      <td>0.959603</td>\n      <td>1.207539</td>\n      <td>1.035909</td>\n      <td>0.000000</td>\n      <td>1.179253</td>\n      <td>0.834440</td>\n    </tr>\n    <tr>\n      <th>W</th>\n      <td>0.474408</td>\n      <td>1.679513</td>\n      <td>0.420888</td>\n      <td>0.402335</td>\n      <td>0.308844</td>\n      <td>0.489493</td>\n      <td>0.681989</td>\n      <td>1.109897</td>\n      <td>0.649373</td>\n      <td>0.374314</td>\n      <td>0.625049</td>\n      <td>0.591486</td>\n      <td>0.425722</td>\n      <td>0.521980</td>\n      <td>0.565894</td>\n      <td>0.416941</td>\n      <td>0.420829</td>\n      <td>1.179253</td>\n      <td>0.000000</td>\n      <td>1.348876</td>\n    </tr>\n    <tr>\n      <th>Y</th>\n      <td>1.654408</td>\n      <td>0.862319</td>\n      <td>1.565089</td>\n      <td>1.474623</td>\n      <td>1.303579</td>\n      <td>1.403907</td>\n      <td>0.986374</td>\n      <td>0.819301</td>\n      <td>1.912586</td>\n      <td>1.496523</td>\n      <td>1.227827</td>\n      <td>1.301236</td>\n      <td>1.518396</td>\n      <td>1.676351</td>\n      <td>1.243503</td>\n      <td>1.493415</td>\n      <td>1.337322</td>\n      <td>0.834440</td>\n      <td>1.348876</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup\n",
    "data = pd.read_csv('../DMS_data/P53_HUMAN_Giacomelli_WT_Nutlin_2018.csv')\n",
    "dat1 = dc.aufteilung_mut_pos(dc.min_max_norm(dc.z_transform(data)))\n",
    "# Distance Matrix\n",
    "dat1 = dc.rmv_na(de.mean_substitutions(dat1))\n",
    "distance_mat: pd.DataFrame = de.dms_distance_matrix(dat1)\n",
    "distance_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T10:38:09.386565Z",
     "start_time": "2023-06-30T10:38:08.865772500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def bench_k_means(kmeans, name, data, labels):\n",
    "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kmeans : KMeans instance\n",
    "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
    "        already set.\n",
    "    name : str\n",
    "        Name given to the strategy. It will be used to show the results in a\n",
    "        table.\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The data to cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        The labels used to compute the clustering metrics which requires some\n",
    "        supervision.\n",
    "    \"\"\"\n",
    "    t0 = time()\n",
    "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n",
    "    fit_time = time() - t0\n",
    "    results = [name, fit_time, estimator[-1].inertia_]\n",
    "\n",
    "    # Define the metrics which require only the true labels and estimator\n",
    "    # labels\n",
    "    clustering_metrics = [\n",
    "        metrics.homogeneity_score,\n",
    "        metrics.completeness_score,\n",
    "        metrics.v_measure_score,\n",
    "        metrics.adjusted_rand_score,\n",
    "        metrics.adjusted_mutual_info_score,\n",
    "    ]\n",
    "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n",
    "\n",
    "    # The silhouette score requires the full dataset\n",
    "    results += [\n",
    "        metrics.silhouette_score(\n",
    "            data,\n",
    "            estimator[-1].labels_,\n",
    "            metric=\"euclidean\",\n",
    "            sample_size=300,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Show the results\n",
    "    formatter_result = (\n",
    "        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
    "    )\n",
    "    print(formatter_result.format(*results))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-30T10:48:43.776434Z",
     "start_time": "2023-06-30T10:48:43.432285600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8, n_init='auto').fit(distance_mat)\n",
    "# pca -> scatter plott"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T13:51:16.264749500Z",
     "start_time": "2023-07-01T13:51:15.901960200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "KMeans(n_init='auto')",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_init=&#x27;auto&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_init=&#x27;auto&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T14:29:55.656086700Z",
     "start_time": "2023-07-01T14:29:54.861791100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "array([7, 4, 0, 0, 5, 5, 2, 3, 7, 0, 2, 6, 0, 7, 6, 0, 5, 3, 5, 1])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T13:53:34.179509400Z",
     "start_time": "2023-07-01T13:53:33.931678200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n       'Q', 'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.feature_names_in_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T13:55:59.473134300Z",
     "start_time": "2023-07-01T13:55:59.218533100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
